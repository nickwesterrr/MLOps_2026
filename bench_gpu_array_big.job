#!/bin/bash
#SBATCH --job-name=bench_big
#SBATCH --partition=gpu_course
#SBATCH --gpus=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=00:20:00
#SBATCH --array=0-6

#SBATCH --output=/home/scur2265/MLOps_2026/experiments/results/question\ 8/model\ changes/big_job/array_big_%A_%a.out
#SBATCH --error=/home/scur2265/MLOps_2026/experiments/results/question\ 8/model\ changes/big_job/array_big_%A_%a.err

set -euo pipefail

# Zorg dat de output directory bestaat
mkdir -p "/home/scur2265/MLOps_2026/experiments/results/question 8/model changes/big_job"

module purge
module load 2025
module load Python/3.13.1-GCCcore-14.2.0
module load CUDA/12.8.0

source .venv/bin/activate

BATCH_SIZES=(8 16 32 64 128 256 512)
BS=${BATCH_SIZES[$SLURM_ARRAY_TASK_ID]}

echo "Running on: $(hostname)"
echo "TaskID=$SLURM_ARRAY_TASK_ID batch_size=$BS"

python -c "import torch; print('torch', torch.__version__); print('cuda_available', torch.cuda.is_available()); print('gpu', torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"

python experiments/benchmark_throughput.py \
  --device cuda \
  --model big \
  --mode forward \
  --split train \
  --batch_size "$BS" \
  --num_workers 2 \
  --steps 50 \
  --warmup_steps 10 \
  --torch_threads $SLURM_CPUS_PER_TASK \
  --pin_memory
