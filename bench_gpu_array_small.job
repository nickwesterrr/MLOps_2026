#!/bin/bash
#SBATCH --job-name=bench_small
#SBATCH --partition=gpu_course
#SBATCH --gpus=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=00:15:00
#SBATCH --array=0-6
#SBATCH --output=experiments/results/array_small_%A_%a.out
#SBATCH --error=experiments/results/array_small_%A_%a.err

set -euo pipefail
mkdir -p experiments/results

module purge
module load 2025


# CUDA-enabled venv
source ../.venv/bin/activate

# Batch sizes (7 stuks: >= 6 vereist)
BATCH_SIZES=(8 16 32 64 128 256 512)
BS=${BATCH_SIZES[$SLURM_ARRAY_TASK_ID]}

echo "Running on: $(hostname)"
echo "TaskID=$SLURM_ARRAY_TASK_ID batch_size=$BS"
python -c "import torch; print('torch', torch.__version__); print('cuda_available', torch.cuda.is_available()); print('gpu', torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"

python experiments/benchmark_throughput.py \
  --device cuda \
  --model small \
  --mode forward \
  --split train \
  --batch_size "$BS" \
  --num_workers 2 \
  --steps 50 \
  --warmup_steps 10 \
  --torch_threads $SLURM_CPUS_PER_TASK \
  --pin_memory
