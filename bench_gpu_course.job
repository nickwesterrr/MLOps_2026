#!/bin/bash
#SBATCH --job-name=pcam_bench_gpu
#SBATCH --partition=gpu_course
#SBATCH --gpus=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=00:10:00
#SBATCH --output=experiments/results/bench_batch_1_gpu_%j.out
#SBATCH --error=experiments/results/bench_batch_1_gpu_%j.err

set -euo pipefail
mkdir -p experiments/results

module purge
module load 2025
module load Python/3.13.1-GCCcore-14.2.0
module load CUDA/12.8.0

# GPU venv (CUDA-enabled torch)
source .venv/bin/activate

echo "Running on: $(hostname)"
echo "SLURM_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK"
nvidia-smi

python -c "import torch; print('torch', torch.__version__); print('cuda_available', torch.cuda.is_available()); print('gpu', torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"

python experiments/benchmark_throughput.py \
  --device cuda \
  --mode forward \
  --split train \
  --batch_size 1 \
  --num_workers 2 \
  --steps 50 \
  --warmup_steps 10 \
  --torch_threads $SLURM_CPUS_PER_TASK \
  --pin_memory
